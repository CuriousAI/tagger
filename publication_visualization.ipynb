{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizations of the learned models\n",
    "\n",
    "In this notebook, one can load two pre-trained models to see how the network is behaving. The following visualizations are the simplified and cleaned up versions of our submitted paper at https://arxiv.org/abs/1606.06724. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's first Define some path to the pre-learned models.\n",
    "MNIST_RUN = './pretrained_models/mnist-results'\n",
    "SHAPES_RUN = './pretrained_models/shapes-results'\n",
    "\n",
    "# Let's enable auto-reload for clarity.\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare the import.\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from utils import AttributeDict\n",
    "import tagger_exp\n",
    "\n",
    "from analyze import analyze_plot_publication"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualization of Network behavior on Shapes50k20x20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# here we have five models to calculate the final AMI score\n",
    "# default override\n",
    "override = AttributeDict(\n",
    "        n_iterations=5,\n",
    "        n_groups=4,\n",
    "        valid_batch_size=1000,\n",
    "        batch_size=1000,\n",
    "    )\n",
    "\n",
    "shapes_exp = tagger_exp.TaggerExperiment.load(SHAPES_RUN, p_override=override)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "it = shapes_exp.streams['valid'].get_epoch_iterator(as_dict=True)\n",
    "mb = next(it)\n",
    "acts = shapes_exp.tagger.eval_acts(mb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from analyze import analyze_plot_publication\n",
    "\n",
    "index_to_plot = acts.clean.ami_score_per_sample[-1].argsort()[100:1000:80][:6][::-1]\n",
    "index_to_zoom = index_to_plot[0]\n",
    "\n",
    "special_pairs = [\n",
    "    {\n",
    "        'acts': acts,\n",
    "        'mb': mb,\n",
    "        'index': 25,\n",
    "    },\n",
    "    {\n",
    "        'acts': acts,\n",
    "        'mb': mb,\n",
    "        'index': 19\n",
    "    },\n",
    "    {\n",
    "        'acts': acts,\n",
    "        'mb': mb,\n",
    "        'index': 50,\n",
    "    }\n",
    "]\n",
    "\n",
    "f = analyze_plot_publication(index_to_zoom, index_to_plot[:6], acts, mb, \n",
    "                             S=(20, 20), specials=special_pairs, saturations_in_z=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_override = AttributeDict(\n",
    "    n_iterations=5,\n",
    "    load_from=None,\n",
    "    n_groups=4,\n",
    "    valid_batch_size=1000,\n",
    "    batch_size=1000,\n",
    "    )\n",
    "mnist_override2 = AttributeDict(\n",
    "    dataset='freq20-1mnist',\n",
    "    load_from=None,\n",
    "    objects_per_sample=1,\n",
    "    n_iterations=5,\n",
    "    n_groups=4,\n",
    "    valid_batch_size=1000,\n",
    "    batch_size=1000,\n",
    "    )\n",
    "\n",
    "mnist_exp = tagger_exp.TaggerExperiment.load(MNIST_RUN, p_override=mnist_override)\n",
    "mnist_exp1 = tagger_exp.TaggerExperiment.load(MNIST_RUN, p_override=mnist_override2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_it = mnist_exp.streams['test'].get_epoch_iterator(as_dict=True)\n",
    "mnist_it2 = mnist_exp1.streams['test'].get_epoch_iterator(as_dict=True)\n",
    "mnist_mb = next(mnist_it)\n",
    "mnist_mb2 = next(mnist_it2)\n",
    "\n",
    "mnist_acts = mnist_exp.tagger.eval_acts(mnist_mb)\n",
    "mnist_acts2 = mnist_exp1.tagger.eval_acts(mnist_mb2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_to_plot = mnist_acts.clean.ami_score_per_sample[-1].argsort()[154:1000:90][3:]\n",
    "\n",
    "index_to_zoom = index_to_plot[-1]\n",
    "\n",
    "special_pairs = [\n",
    "    {\n",
    "        'acts': mnist_acts2,\n",
    "        'mb': mnist_mb2,\n",
    "        'index': 19\n",
    "    },\n",
    "    {\n",
    "        'path_x': './pretrained_models/mnist-results/mnist_removal_example_v3.npz',\n",
    "        'type': 'm'\n",
    "    },\n",
    "    {\n",
    "        'path_x': './pretrained_models/mnist-results/mnist_removal_example_v3.npz',\n",
    "        'type': 'm_removed'\n",
    "    }\n",
    "]\n",
    "\n",
    "f = analyze_plot_publication(index_to_zoom, index_to_plot[::-1], mnist_acts, mnist_mb, \n",
    "                             S=(28, 28), specials=special_pairs, plot_classification=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
