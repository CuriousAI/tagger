{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Freq20-MNIST1/2 dataset generation script."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prepare the import & setup the directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division, print_function, unicode_literals\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import h5py\n",
    "from fuel.datasets import MNIST\n",
    "from scipy.ndimage import convolve\n",
    "from scipy.ndimage.filters import gaussian_filter\n",
    "\n",
    "from itertools import product\n",
    "from fuel.converters.base import fill_hdf5_file\n",
    "from fuel.datasets import IndexableDataset\n",
    "\n",
    "import os.path\n",
    "import os\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = './'\n",
    "%cd ..\n",
    "\n",
    "# please make sure we are at the root directory of the project.\n",
    "%pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Texture Generation Functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gen texture\n",
    "def gen_textures(freqs, size, func, normalize=True):\n",
    "    \"\"\" Generate 2D textures from frequency tuples\n",
    "    freqs: (n_textures, locs_per_texture, 2)\n",
    "    \"\"\"\n",
    "    N = len(freqs)\n",
    "    S = size\n",
    "    z = np.zeros((N, S, S), 'complex64')\n",
    "    for i in range(N):\n",
    "        for loc in freqs[i]:\n",
    "            z[i, loc[0], loc[1]] += func()\n",
    "\n",
    "    spat = np.float32(np.real(np.fft.ifft2(z)))\n",
    "    if normalize:\n",
    "        spat -= spat.min((1, 2), keepdims=True)\n",
    "        spat /= spat.max((1, 2), keepdims=True)\n",
    "    return spat\n",
    "\n",
    "def gauss_filt(fs, std):\n",
    "    inp = np.zeros((fs, fs))\n",
    "    inp[fs//2, fs//2] = 1.\n",
    "    return gaussian_filter(inp, std)\n",
    "\n",
    "\n",
    "# choose_freqs\n",
    "def choose_freqs(n, n_freqs_per_texture, texture_size, conv_filt_size, conv_filt_std, rng=np.random):\n",
    "    S = texture_size\n",
    "\n",
    "    # Special case for a pair of single freq textures\n",
    "    if n <= 2 and n_freqs_per_texture == 1:\n",
    "        too_close = True\n",
    "        retries_left = 100\n",
    "        while too_close and retries_left > 0:\n",
    "            # Initial guess\n",
    "            x = rng.randint(low=1, high=S-1, size=(n))\n",
    "            y = rng.randint(low=1, high=S//2-4, size=(n))\n",
    "            if True:\n",
    "                diffs = np.array([np.abs(x[i] - x[j]) for i in range(n) for j in range(i+1, n)])\n",
    "\n",
    "                assert len(diffs) <= 1\n",
    "                if np.any(diffs < 10):\n",
    "                    retries_left -= 1\n",
    "                    continue\n",
    "            too_close = False\n",
    "        res = np.concatenate([x[None], y[None]], 0).T\n",
    "\n",
    "        if retries_left == 0:\n",
    "            logger.warning('Used all the retries in data generation. Still did not get good one')\n",
    "\n",
    "        return res[:, None, :]\n",
    "\n",
    "    # Special case for three freqs per observation\n",
    "    if n == 3 and n_freqs_per_texture == 1:\n",
    "        # Y is always random\n",
    "        y = rng.randint(low=1, high=S//2-4, size=(n))\n",
    "        # X is handled in n segments\n",
    "        min_dist = S/5\n",
    "        x = -min_dist + 1\n",
    "        xs = []\n",
    "        for s in range(n):\n",
    "            high = S - 1 - min_dist * (n - 1 - s)\n",
    "            low = x + min_dist\n",
    "            x = rng.randint(low=low, high=high, size=(1))\n",
    "            xs += [x]\n",
    "        x = rng.permutation(np.array(xs)[:, 0])\n",
    "        y = rng.randint(low=1, high=S//2-4, size=(n))\n",
    "        assert x.shape == y.shape\n",
    "        res = np.concatenate([x[None], y[None]], 0).T\n",
    "        return res[:, None, :]\n",
    "\n",
    "    N = n * 10\n",
    "\n",
    "    # Initial guess\n",
    "    freqs = rng.randint(low=1, high=S-1, size=(N, n_freqs_per_texture, 2))\n",
    "\n",
    "    texture_candidates = gen_textures(freqs, S, lambda: 1)\n",
    "    # Get symmetric frequencies\n",
    "    symm = np.abs(np.fft.fft2(texture_candidates))\n",
    "    # remove DC\n",
    "    symm[:, 0, 0] = 0\n",
    "    # Expand the points with a gaussian filter\n",
    "    filt = gauss_filt(conv_filt_size, conv_filt_std)\n",
    "    symm_conv = convolve(symm, filt[None])\n",
    "\n",
    "    permutations = [rng.permutation(np.arange(N)) for _ in range(10)]\n",
    "\n",
    "    max_val = np.max(symm_conv)\n",
    "\n",
    "    best_indices = []\n",
    "    for perm in permutations:\n",
    "        final_indices = []\n",
    "        mask = np.zeros((S, S))\n",
    "        for i in perm:\n",
    "            im = symm_conv[i]\n",
    "            if np.max(mask + im) > max_val:\n",
    "                continue\n",
    "            final_indices += [i]\n",
    "            mask += im\n",
    "        if len(final_indices) > len(best_indices):\n",
    "            best_indices = final_indices\n",
    "    return freqs[best_indices]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Texture + MNIST script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TexturedMNIST(IndexableDataset):\n",
    "    def __init__(self, which_sets, n_digits=1, scale=1., textures=None,\n",
    "                 **kwargs):\n",
    "        assert len(which_sets) == 1, 'Only one concurrent set implemented'\n",
    "        seed_inc, n = {'train': (0, 50000),\n",
    "                       'valid': (1, 10000),\n",
    "                       'test': (2, 10000)}[which_sets[0]]\n",
    "        rng = np.random.RandomState(1 + seed_inc)\n",
    "\n",
    "        if which_sets == ['valid']:\n",
    "            rang = range(50000, 60000)\n",
    "            which_sets = ['train']\n",
    "        else:\n",
    "            rang = range(n)\n",
    "\n",
    "        # Get the whole MNIST data and prepare a dataset\n",
    "        mnist = MNIST(which_sets)\n",
    "        orig_feats, labs = mnist.get_data(None, rang)\n",
    "\n",
    "        S = orig_feats.shape[-1]\n",
    "        if scale == 1.:\n",
    "            pass\n",
    "        elif scale == 2.:\n",
    "            S = int(S * scale)\n",
    "        else:\n",
    "            raise NotImplemented\n",
    "        N = len(rang)\n",
    "        m = n_digits\n",
    "        if textures is None:\n",
    "            codes = TexturedMNIST.create_textures(N, S, m + 1, rng)\n",
    "        else:\n",
    "            codes = TexturedMNIST.load_textures(textures, N, S, m + 1, rng)\n",
    "\n",
    "        masks_independent, perm, perm_top_bottom = TexturedMNIST.create_masks(orig_feats, scale, m, rng)\n",
    "        labs = np.concatenate([labs[p] for p in perm], axis=1)\n",
    "        if perm_top_bottom is not None:\n",
    "            assert labs.shape[1] == 2\n",
    "            perm_top_bottom = perm_top_bottom.astype(labs.dtype).reshape(perm_top_bottom.shape[0:2])\n",
    "            labs_inv = labs[:, ::-1]\n",
    "            labs = (perm_top_bottom * labs + (1 - perm_top_bottom) * labs_inv).astype(labs.dtype)\n",
    "        feats, masks = TexturedMNIST.compose(codes, masks_independent)\n",
    "\n",
    "        self.sources = ['features', 'targets', 'mask', 'codes']\n",
    "        self.data_sources = [feats, labs, masks, codes]\n",
    "        super(TexturedMNIST, self).__init__(\n",
    "            indexables={'features': feats, 'targets': labs,\n",
    "                        'mask': masks, 'codes': codes}, **kwargs)\n",
    "\n",
    "    @staticmethod\n",
    "    def create_masks(feats, scale, m, rng, shift=True):\n",
    "        if scale != 1.:\n",
    "            W, H = feats.shape[-2:]\n",
    "            feats2x = np.ones(feats.shape[:2] + (W*scale, H*scale))\n",
    "            feats2x[:, :, 0::2, 0::2] = feats\n",
    "            feats2x[:, :, 1::2, 0::2] = feats\n",
    "            feats2x[:, :, 0::2, 1::2] = feats\n",
    "            feats2x[:, :, 1::2, 1::2] = feats\n",
    "            feats = feats2x\n",
    "        mask = np.float32(feats / 1.)\n",
    "        assert np.min(mask) == 0\n",
    "        print(np.max(mask))\n",
    "        assert np.max(mask) == 1.\n",
    "        if m == 1:\n",
    "            if shift:\n",
    "                mask = TexturedMNIST.shift_ims(mask, -shift, -shift)\n",
    "            return mask[:, None], [np.asarray(range(mask.shape[0]))], None\n",
    "        elif m == 2:\n",
    "            shift = 2 * scale\n",
    "            perm = [rng.permutation(mask.shape[0]), rng.permutation(mask.shape[0])]\n",
    "            m1 = mask[perm[0]]\n",
    "            m2 = mask[perm[1]]\n",
    "            if shift:\n",
    "                m1 = TexturedMNIST.shift_ims(m1, -shift, -shift)\n",
    "                m2 = TexturedMNIST.shift_ims(m2, shift, shift)\n",
    "\n",
    "            # Shuffle top vs. bottom digit\n",
    "            m_12 = np.concatenate([m1[:, None], m2[:, None]], 1)\n",
    "            m_21 = np.concatenate([m2[:, None], m1[:, None]], 1)\n",
    "            perm_top_bottom = np.reshape(rng.binomial(1, 0.5, mask.shape[0]), (mask.shape[0],) + (1,) * mask.ndim)\n",
    "            m = np.float32(perm_top_bottom * m_12 + (1 - perm_top_bottom) * m_21)\n",
    "            return m, perm, perm_top_bottom\n",
    "\n",
    "    @staticmethod\n",
    "    def create_textures(N, S, m, rng):\n",
    "        freqs = [choose_freqs(m, n_freqs_per_texture=1, texture_size=S,\n",
    "                              conv_filt_size=5, conv_filt_std=1, rng=rng) for _ in range(N)]\n",
    "\n",
    "        # Squash the first two dims\n",
    "        freqs = np.concatenate(freqs, 0)\n",
    "        textures = gen_textures(freqs, S, lambda: np.exp(2j * np.pi * rng.rand()))\n",
    "        return textures.reshape(N, m, 1, S, S)\n",
    "\n",
    "    @staticmethod\n",
    "    def load_textures(textures_name, N, S, m, rng):\n",
    "        codes = np.zeros((N * m, S, S), dtype=np.float32)\n",
    "        with h5py.File(textures_name, 'r') as f:\n",
    "            textures = f['textures'][:]\n",
    "            nr_textures, _, W, H = textures.shape\n",
    "            idxs = rng.randint(0, nr_textures, N*m)\n",
    "            w_offsets = rng.randint(0, W-S, N*m)\n",
    "            h_offsets = rng.randint(0, H-S, N*m)\n",
    "            for i, (j, w, h) in enumerate(zip(idxs, w_offsets, h_offsets)):\n",
    "                codes[i] = textures[j, 0, h:h+S, w:w+S]\n",
    "        return codes.reshape((N, m, 1, S, S))\n",
    "\n",
    "    @staticmethod\n",
    "    def compose(textures, masks_independent):\n",
    "        \"\"\" Use the first texture as bg \"\"\"\n",
    "        # textures.shape == (N, n_layers, ...)\n",
    "        assert textures.shape[1] == masks_independent.shape[1] + 1\n",
    "\n",
    "        masks = np.ones(textures.shape, dtype='float32')\n",
    "        res = textures[:, 0]\n",
    "        for i in range(1, textures.shape[1]):\n",
    "            m = masks_independent[:, i - 1]\n",
    "            masks[:, i] = m\n",
    "            for j in range(i):\n",
    "                masks[:, j] *= 1 - m\n",
    "            t = textures[:, i]\n",
    "            res = m * t + (1 - m) * res\n",
    "        assert np.allclose(np.sum(masks, axis=1), 1)\n",
    "        return res, masks\n",
    "\n",
    "    @staticmethod\n",
    "    def shift_ims(ims, x, y):\n",
    "        assert x % 1 == 0, 'Shift has to be integer'\n",
    "        assert y % 1 == 0, 'Shift has to be integer'\n",
    "        (x, y) = (int(x), int(y))\n",
    "        # TODO: This would be faster in uint8\n",
    "        assert ims.ndim == 4\n",
    "        if x > 0:\n",
    "            x_slice = np.zeros((ims.shape[0], ims.shape[1], ims.shape[2], x),\n",
    "                                  dtype='float32')\n",
    "            ims = np.concatenate([x_slice, ims[:, :, :, :-x]], 3)\n",
    "        if x < 0:\n",
    "            x_slice = np.zeros((ims.shape[0], ims.shape[1], ims.shape[2], -x),\n",
    "                                  dtype='float32')\n",
    "            ims = np.concatenate([ims[:, :, :, -x:], x_slice], 3)\n",
    "\n",
    "        if y > 0:\n",
    "            y_slice = np.zeros((ims.shape[0], ims.shape[1], y, ims.shape[3]),\n",
    "                                  dtype='float32')\n",
    "            ims = np.concatenate([y_slice, ims[:, :, :-y, :]], 2)\n",
    "        if y < 0:\n",
    "            y_slice = np.zeros((ims.shape[0], ims.shape[1], -y, ims.shape[3]),\n",
    "                                  dtype='float32')\n",
    "            ims = np.concatenate([ims[:, :, -y:, :], y_slice], 2)\n",
    "\n",
    "        return ims"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple Visualization Script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show(ims, titles=None):\n",
    "    if not isinstance(ims, (tuple, list)):\n",
    "        ims = [ims]\n",
    "    if titles is None:\n",
    "        titles = [''] * len(ims)\n",
    "    if not isinstance(titles, (tuple, list)):\n",
    "        titles = [titles]\n",
    "        \n",
    "    H = int(np.sqrt(len(ims)))\n",
    "    W = int(round(len(ims) / H))\n",
    "    #print(\"{} x {} = {} >= {}\".format(W, H, W*H, len(ims)))\n",
    "    fig, axes = plt.subplots(nrows=H, ncols=W, figsize=(3*W, 3*H))\n",
    "    if len(ims) == 1:\n",
    "        axes = np.array([axes])\n",
    "    for im, ax, title in zip(ims, axes.flatten(), titles):\n",
    "        if len(im.shape) == 3:\n",
    "            assert im.shape[0] == 1\n",
    "            im = im[0]\n",
    "        ax.matshow(im, cmap=\"gray\")\n",
    "        ax.set_xticks([])\n",
    "        ax.set_yticks([])\n",
    "        ax.set_title(title)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Textures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = np.random.RandomState(546298)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "freqs = np.array(list(product([ 4, 10, 21, 32, 37], [ 0,  4, 8, 12])))\n",
    "\n",
    "freqs = freqs[:20].reshape((5, 4, 2))\n",
    "freqs[:, :, 1] += np.arange(freqs.shape[0])[:, None]\n",
    "freqs = np.concatenate(freqs, 0)[:, None, :]\n",
    "freqs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "textures = gen_textures(freqs, np.max(freqs) + 1, lambda: np.exp(2j * np.pi * rng.rand()))\n",
    "show([t for t in textures], titles=['({},{})'.format(f1, f2) for f1, f2 in freqs[:, 0]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data(nr_digits, scale, orig_feats, labs, textures, shift, rng=None):\n",
    "    rng = np.random.RandomState(14579) if rng is None else rng\n",
    "        \n",
    "    S = int(scale * orig_feats.shape[-1])\n",
    "    tex_S = textures.shape[-1]\n",
    "    N = orig_feats.shape[0]\n",
    "    allN = np.arange(N)\n",
    "    \n",
    "    masks, mask_idxs, perm_top_bottom = TexturedMNIST.create_masks(orig_feats, scale, nr_digits, rng, shift=shift)\n",
    "    mask_idxs = np.array(mask_idxs)\n",
    "    print(mask_idxs.shape)\n",
    "    #mask_idxs = np.concatenate([rng.permutation(allN)[None] for i in range(nr_digits)], 0) \n",
    "\n",
    "    if nr_digits == 2:\n",
    "        z_order = np.concatenate([perm_top_bottom, (1 - perm_top_bottom)], axis=1)\n",
    "        z_order = np.transpose(np.reshape(z_order, z_order.shape[0:2]), (1, 0))\n",
    "    else:\n",
    "        assert nr_digits == 1\n",
    "        z_order = np.zeros((nr_digits, N), dtype=np.int)\n",
    "        for i in allN:\n",
    "            z_order[:, i] = rng.permutation(np.arange(nr_digits))  \n",
    "    \n",
    "    targets = np.concatenate([labs[mask_idxs[(z_order[i], allN)]] for i in range(nr_digits)], 1) \n",
    "    shuffled_masks = np.concatenate([masks[(allN, z_order[i])][:, :, None] for i in range(nr_digits)], 1)\n",
    "    \n",
    "    \n",
    "    idxs = np.arange(textures.shape[0])\n",
    "    code_idxs = np.array([rng.choice(idxs, size=(nr_digits+1), replace=False) for i in allN])\n",
    "    \n",
    "    rnd = np.random.RandomState(598)\n",
    "\n",
    "    codes = np.zeros((N, nr_digits+1, 1, S, S))\n",
    "    for i in range(N):\n",
    "        for j in range(nr_digits+1):\n",
    "            xs, ys = rnd.randint(0, tex_S - S + 1, 2)\n",
    "            codes[i, j, 0, :, :] = textures[code_idxs[i, j], xs:xs+S, ys:ys+S]\n",
    "    \n",
    "    feats, masks = TexturedMNIST.compose(codes, shuffled_masks)\n",
    "    \n",
    "    return feats.astype(np.float32), targets.astype(np.int64), code_idxs.astype(np.int64), masks.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_as_fuel(filename, feats, code_idxs, targets, masks, \n",
    "                 feats_test, targets_test, code_idxs_test, masks_test, \n",
    "                 trainsize=50000, valsize=10000):\n",
    "    split = (\n",
    "        ('train', 'features', feats[:trainsize]),\n",
    "        ('train', 'mask', masks[:trainsize]),\n",
    "        ('train', 'codes', code_idxs[:trainsize]),\n",
    "        ('train', 'targets', targets[:trainsize]),\n",
    "\n",
    "        ('valid', 'features', feats[trainsize:trainsize+valsize]),\n",
    "        ('valid', 'mask', masks[trainsize:trainsize+valsize]),\n",
    "        ('valid', 'codes', code_idxs[trainsize:trainsize+valsize]),\n",
    "        ('valid', 'targets', targets[trainsize:trainsize+valsize]),\n",
    "\n",
    "        ('test', 'features', feats_test),\n",
    "        ('test', 'mask', masks_test),\n",
    "        ('test', 'codes', code_idxs_test),\n",
    "        ('test', 'targets', targets_test),\n",
    "    )\n",
    "\n",
    "    with h5py.File(os.path.join(data_dir, filename), mode='w') as f:\n",
    "        fill_hdf5_file(f, split)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compress_fuel(source_filename, target_filename):\n",
    "    source = h5py.File(os.path.join(data_dir, source_filename), mode='r')\n",
    "    target = h5py.File(os.path.join(data_dir, target_filename), mode='w')\n",
    "    for data in source:\n",
    "        print('converting {}'.format(data))\n",
    "        target.create_dataset(data, data=source[data][:], compression='gzip')\n",
    "    for attr in source.attrs:\n",
    "        target.attrs[attr] = source.attrs[attr]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the whole MNIST data\n",
    "mnist = MNIST(['train'])\n",
    "orig_feats, labs = mnist.get_data(None, range(60000))\n",
    "\n",
    "mnist = MNIST(['test'])\n",
    "test_feats, test_labs = mnist.get_data(None, range(10000))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normal 2 digit dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nr_digits = 2\n",
    "scale = 1\n",
    "S = int(scale * orig_feats.shape[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feats, targets, code_idxs, masks = prepare_data(nr_digits, scale, orig_feats, labs, textures, True,\n",
    "                                                rng=np.random.RandomState(52698))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subs = slice(2, 6)\n",
    "show(list(feats[subs]) + list(masks[subs, 0])  + list(masks[subs, 1])  + list(masks[subs, 2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feats_test, targets_test, code_idxs_test, masks_test = prepare_data(nr_digits, scale, test_feats, test_labs, textures, True,\n",
    "                                                                    rng=np.random.RandomState(2938))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subs = slice(2, 6)\n",
    "show(list(feats_test[subs]) + list(masks_test[subs, 0])  + list(masks_test[subs, 1])  + list(masks_test[subs, 2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save as Fuel HDF5\n",
    "save_as_fuel('freq20-2MNIST.h5', feats, code_idxs, targets, masks,\n",
    "             feats_test, targets_test, code_idxs_test, masks_test,\n",
    "             50000, 10000)\n",
    "# Compress\n",
    "compress_fuel('freq20-2MNIST.h5', 'freq20-2MNIST_compressed.h5')\n",
    "!rm {os.path.join(data_dir, 'freq20-2MNIST.h5')}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 digit Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nr_digits = 1\n",
    "scale = 1\n",
    "S = int(scale * orig_feats.shape[-1])\n",
    "\n",
    "feats_single, targets_single, code_idxs_single, masks_single = prepare_data(\n",
    "    nr_digits, scale, orig_feats, labs, textures, False, rng=np.random.RandomState(52698))\n",
    "\n",
    "subs = slice(2, 6)\n",
    "show(list(feats_single[subs]) + list(masks_single[subs, 0])  + list(masks_single[subs, 1]))\n",
    "feats_single_test, targets_single_test, code_idxs_single_test, masks_single_test = prepare_data(nr_digits, scale, test_feats, test_labs, textures, False,\n",
    "                                                                    rng=np.random.RandomState(2938))\n",
    "\n",
    "save_as_fuel('freq20-1MNIST.h5', feats_single, code_idxs_single, targets_single, masks_single,\n",
    "             feats_single_test, targets_single_test, code_idxs_single_test, masks_single_test,\n",
    "             50000, 10000)\n",
    "\n",
    "compress_fuel('freq20-1MNIST.h5', 'freq20-1MNIST_compressed.h5')\n",
    "!rm {os.path.join(data_dir, 'freq20-1MNIST.h5')}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
